server <- function(input,output,session){
  source("R/SourceAll.R",local=T)

  # fill session_if textOutput with current session$token
  output$session_id <- renderText({
      paste0("Current session: ", session$token)
  })

  # getCurrentVersion(updateDESCRIPTION=T) # Where to Place this ? So it does not always get 'updated'?
  # Can we add this somehow as necassary to every new release?

# Security section ----
  options(shiny.maxRequestSize=20*(1024^2)) # request 20MB

  #### Clean Up
  # create www folder if not present
  if(dir.exists("www")){
    setwd("www")
    # create folder with session tokes as name for all files to be saved inside
    if(!dir.exists(session$token)){
      dir.create(session$token)
      # create REport.md
        write(
            paste0(
            "# ShinyOmics Report (",format(Sys.Date(),'%d/%m/%Y'),")\n\n",
            "This is a report generated by the ",
            "<a href='",
            SERVER,
            "' target='_blank'>cOmicsART</a>",
            " application under version ",
            VERSION,
            ".\n Documentation on the user interface can be found ",
            "<a href='",
            DOCUMENTATION,
            "' target='_blank'>here</a>.\n\n"
            ),
            file=paste0(session$token,"/Report.md")
        )
      print(paste0("Created folder for session: ",session$token))
    } else {
      # remove all files in the folder
      setwd(session$token)
      list <- list.files()
      file.remove(list.files(path="."))
      print("Removed old files for fresh start")
      setwd("..")
    }
    file_path <- paste0("/www/",session$token,"/")
    print(list.files())
    file.remove(
      list.files(path=".") %>%
        setdiff(list.files(path=".", pattern = ".csv")) %>%
        setdiff(list.files(path=".", pattern = ".RDS")) %>%
        setdiff(list.files(path=".", pattern = ".png")) %>%
        setdiff(list.files(path=".", pattern = ".gif"))
    )
    print("Removed old Report files for fresh start")
    setwd("..")
  }
  observe_helpers()
  
  
# Download Report pdf ----
  DownloadReport_server("DownloadTestModule")
  
# Layout upon Start ----
  hideTab(inputId = "tabsetPanel1", target = "Pre-processing")
  hideTab(inputId = "tabsetPanel1", target = "Sample Correlation")
  hideTab(inputId = "tabsetPanel1", target = "Significance Analysis")
  hideTab(inputId = "tabsetPanel1", target = "PCA")
  hideTab(inputId = "tabsetPanel1", target = "Heatmap")
  hideTab(inputId = "tabsetPanel1", target = "Single Gene Visualisations")
  hideTab(inputId = "tabsetPanel1", target = "Enrichment Analysis")
  shinyjs::hide("mainPanel_DataSelection")
  
# Init res_tmp and par_tmp objects if they do not yet exist ----
  if(!exists("res_tmp")){
    res_tmp <<- list()
    par_tmp <<- list()
  }
  # create an empty list in res/par_tmp[[session$token]]
  res_tmp[[session$token]] <<- list()
  par_tmp[[session$token]] <<- list()
  # On session end, remove the list from res/par_tmp
  session$onSessionEnded(function() {
    res_tmp[[session$token]] <<- NULL
    par_tmp[[session$token]] <<- NULL
    # delete the folder with the session token
    if(dir.exists(paste0("www/",session$token))){
      # Remove the directory and its contents
      unlink(paste0("www/",session$token), recursive = TRUE)
      if (!dir.exists(paste0("www/",session$token))) {
        cat("The directory has been successfully removed.\n")
      } else {
        cat("The directory could not be removed.\n")
      }
    }
  })
# Init update Object ----
  # updating is a reative value that counts up whenever data is updated
  # this is used to trigger the update of the servers
  updating <- reactiveValues(count = 0)
## Quit App Button ----
  observeEvent(input$Quit_App,{
    showModal(
      modalDialog(
        tags$h4('You can download the complete report by clicking on the link'),
        footer=tagList(
          a(
            href="Report.html", 
            "Download report", 
            download=NA, 
            target="_blank"
          ),
          actionButton(
            inputId = "Done",
            label = "Done"
          ),
          modalButton('Cancel')
        )
      )
    )
  })
  
  observeEvent(input$Done,{
    removeModal()
    show_toast(
      title = "Good Bye!",
      type = "success",
      position = "top",
      timerProgressBar = FALSE,
      width = "100%"
      )
    session$close()
  })
  
# Data Upload + checks ----
  print("Data Upload")

## Set reactiveVals ----
  uploaded_from <- reactiveVal(NULL)
  omic_type <- reactiveVal(NULL)

  output$SaveInputAsList <- downloadHandler(
   filename = function() {
     paste0(input$omic_type, "_only_precompiled", " ", Sys.time(), ".RDS") },
    content = function(file){
      # TODO Q: What to save here? only original enough?
      saveRDS(
        object = res_tmp[[session$token]]$data_original,
        file = file
      )
    }
  )
  
  observeEvent(omic_type(),{
    output$AddGeneSymbols_ui <- NULL
    output$AddGeneSymbols_organism_ui <- NULL
    if(omic_type() == "Transcriptomics"){
      output$AddGeneSymbols_ui <- renderUI({
        actionButton(
          inputId = "AddGeneSymbols",
          label = "Add Gene Annotation"
        )
      })
      output$AddGeneSymbols_organism_ui <- renderUI({selectInput(
        inputId = "AddGeneSymbols_organism",
        label = "Which Organisms?",
        # choices = listDatasets(useEnsembl(biomart = "genes"))[,"description"],
        choices = c("Mouse genes (GRCm39)", "Human genes (GRCh38.p14)"),
        selected = "Mouse genes (GRCm39)"
      )})
    }
  })

  observeEvent(input$AddGeneSymbols, {
    req(data_input_shiny())
    req(res_tmp[[session$token]]$data_original)
    annotation_result <- detect_annotation(res_tmp[[session$token]]$data_original)
    annotation_name <- annotation_result$AnnoType
    column_name <- annotation_result$AnnoCol

    showModal(modalDialog(
      title = "Gene Annotation",
      HTML(paste0(
        "We tried to find an appropriate annotation and ",
        if (is.null(annotation_name)) {
          "found nothing."
        } else {
          paste0("might have found <strong>", annotation_name, "</strong> in <strong>", column_name, "</strong>. Is that correct?")
        }
      )),
      fluidRow(
        column(6, selectInput(
          inputId = "annotation_name",
          label = "Gene Annotation",
          choices = c("entrezgene_id", "ensembl_gene_id", "Symbol"),
          selected = annotation_name
        )),
        column(6, selectInput(
          inputId = "annotation_colname",
          label = "Column Names",
          choices = colnames(rowData(res_tmp[[session$token]]$data_original)),
          selected = column_name
        ))
      ),
      footer = tagList(
        modalButton("Close"),
        actionButton(
          inputId = "do_annotation",
          label = "Do annotation"
        )
      )
    ))
  })

  observeEvent(input$do_annotation, {
    # Added gene annotation if asked for
    if(input$AddGeneSymbols & input[[paste0("omic_type_", uploaded_from())]] == "Transcriptomics") {
      fun_LogIt(
        message = "**DataInput** - Gene Annotation (SYMBOL and gene type) was added"
      )
      fun_LogIt(
        message = paste0("**DataInput** - chosen Organism: ", input$AddGeneSymbols_organism)
      )
      par_tmp[[session$token]]['organism'] <<- input$AddGeneSymbols_organism

      output$debug <- renderText({"<font color=\"#00851d\"><b>Added gene annotation</b></font>"})
      if(par_tmp[[session$token]]['organism'] == "Human genes (GRCh38.p14)"){
        ensembl_slot <- "hsapiens_gene_ensembl"
      }else{
        ensembl_slot <- "mmusculus_gene_ensembl"
      }

      ensembl <- loadedVersion[[ensembl_slot]]$ensmbl
      out <- getBM(
        attributes = c("ensembl_gene_id", "gene_biotype", "external_gene_name", "entrezgene_id"),
        filter = input$annotation_name,
        values = rowData(res_tmp[[session$token]]$data_original)[,input$annotation_colname],
        mart = ensembl
      )
      # Align the rows based on matching annotation
      match_indices <- match(
        rowData(res_tmp[[session$token]]$data_original)[,input$annotation_colname], out[,input$annotation_name]
      )
      matched_out <- out[match_indices, ]

      if (all(is.na(matched_out$ensembl_gene_id))) {
        # Most likely wrong organism used
        output$debug <- renderText({"<font color=\"#ab020a\"><b>You have most likely chosen the wrong organism! No annotation was added</b></font>"})
      } else {
        # Initialize new columns in the rowData with NA
        rowData(res_tmp[[session$token]]$data_original)$ensembl_gene_id <<- NA
        rowData(res_tmp[[session$token]]$data_original)$gene_biotype <<- NA
        rowData(res_tmp[[session$token]]$data_original)$external_gene_name <<- NA
        rowData(res_tmp[[session$token]]$data_original)$entrezgene_id <<- NA

        # Update rowData with matched information
        matched_rows <- !is.na(match_indices)
        rowData(res_tmp[[session$token]]$data_original)$ensembl_gene_id[matched_rows] <<- matched_out$ensembl_gene_id[matched_rows]
        rowData(res_tmp[[session$token]]$data_original)$gene_biotype[matched_rows] <<- matched_out$gene_biotype[matched_rows]
        rowData(res_tmp[[session$token]]$data_original)$external_gene_name[matched_rows] <<- matched_out$external_gene_name[matched_rows]
        rowData(res_tmp[[session$token]]$data_original)$entrezgene_id[matched_rows] <<- matched_out$entrezgene_id[matched_rows]
      }
    }
    
    # edit annotation columns such that if na is present in the row annotation,
    # the na gets replaced by the rowname
    for(i in 1:ncol(rowData(res_tmp[[session$token]]$data))){
      if(any(is.na(rowData(res_tmp[[session$token]]$data)[,i]))){
        rowData(res_tmp[[session$token]]$data)[is.na(rowData(res_tmp[[session$token]]$data)[,i]),i] <<- rownames(res_tmp[[session$token]]$data)[is.na(rowData(res_tmp[[session$token]]$data)[,i])]
      }
    }
    
    for(i in 1:ncol(rowData(res_tmp[[session$token]]$data_original))){
      if(any(is.na(rowData(res_tmp[[session$token]]$data_original)[,i]))){
        rowData(res_tmp[[session$token]]$data_original)[is.na(rowData(res_tmp[[session$token]]$data_original)[,i]),i] <<- rownames(res_tmp[[session$token]]$data_original)[is.na(rowData(res_tmp[[session$token]]$data_original)[,i])]
      }
    }
    
    par_tmp[[session$token]]['addedGeneAnno'] <<- TRUE
    par_tmp[[session$token]]['organism'] <<- input$AddGeneSymbols_organism
    removeModal()
  })

  # Observer to toggle visibility of the download button and helper
  observe({
    if (is.null(uploaded_from())) {
      shinyjs::hide("SaveInputAsRDS")
    }
    req(uploaded_from())
    if (uploaded_from() == "metadata" || uploaded_from() == "file_input") {
      shinyjs::show("SaveInputAsRDS")
    } else {
      shinyjs::hide("SaveInputAsRDS")
    }
  })

  # Observer to toggle visibility of the complete main panel
  observe({
      if (input$refresh1 > 0) {
        req(data_input_shiny() == "DataUploadSuccesful")
        shinyjs::show("mainPanel_DataSelection")
      } else {
        shinyjs::hide("mainPanel_DataSelection")
      }
  })
  
## Upload visual inspection ----
  observeEvent(input$inspect_data, {
    showModal(modalDialog(
      title = "Upload Visual Inspection",
      helpText("If you have uploaded your data, you might want to visually check the tables to confirm the correct data format. If you notice irregualarities you will need to correct the input data - this cannot be done in ShinyOmics, See the help on how your data is expected."),
      br(),
      actionButton(
        inputId = "DoVisualDataInspection",
        label = "Upload data for visual inspection"
      ) %>% helper(type = "markdown", content = "DataSelection_UploadInspection"),
      splitLayout(
        style = "border: 1px solid silver:", cellWidths = c("70%", "30%"),
        DT::dataTableOutput("DataMatrix_VI"),
        htmlOutput(outputId = "DataMatrix_VI_Info", container = pre)
      ),
      splitLayout(
        style = "border: 1px solid silver:", cellWidths = c("70%", "30%"),
        DT::dataTableOutput("SampleMatrix_VI"),
        htmlOutput(outputId = "SampleMatrix_VI_Info", container = pre)
      ),
      splitLayout(
        style = "border: 1px solid silver:", cellWidths = c("70%", "30%"),
        DT::dataTableOutput("EntitieMatrix_VI"),
        htmlOutput(outputId = "EntitieMatrix_VI_Info", container = pre)
      ),
      htmlOutput(outputId = "OverallChecks", container = pre),
      easyClose = TRUE,
      footer = modalButton("Close"),
      size = "l", # large modal
      class = "custom-modal" # custom class for this modal
    ))
  })
  
  observeEvent(input$DoVisualDataInspection,{
    if(isTruthy(input$data_preDone)){
      output$DataMatrix_VI_Info <- renderText({
        "Visual Inspection only for primary data, not for precompiled set possible!"
      })
      req(F)
    }
    if(!(isTruthy(input$data_matrix1) & 
         (isTruthy(input$data_sample_anno1)|isTruthy(input$metadataInput)) & 
         isTruthy(input$data_row_anno1))){
      output$DataMatrix_VI_Info <- renderText(
        "The Upload has failed completely, or you haven't uploaded anything yet. Need to uploade all three matrices!"
        )
    } else {
      flag_csv <- F
      tryCatch(
        expr = {
          Matrix <- read_file(input$data_matrix1$datapath, check.names=T)
          Matrix2 <- read_file(input$data_matrix1$datapath, check.names=F)
          flag_csv <- T
        },
        error = function(){
          print("Not a real csv file!")
          Matrix <- read.table(input$data_matrix1$datapath,check.names = T)
          Matrix2 <- read.table(input$data_matrix1$datapath, check.names = F)
        }
      )

      output$DataMatrix_VI <- DT::renderDataTable({DT::datatable(data = Matrix)})
      output$DataMatrix_VI_INFO <- renderText({"Matrix:"})
      if(isTruthy(input$data_sample_anno1)){
        sample_table <- read_file(input$data_sample_anno1$datapath, check.names=T)
      } else if(isTruthy(input$metadataInput)){
        sample_table <- fun_readInSampleTable(input$metadataInput$datapath)
      } else {
        sample_table <- data.frame()
      }

      output$SampleMatrix_VI <- DT::renderDataTable({DT::datatable(data = sample_table)})
      output$SampleMatrix_VI_INFO <- renderText({"Sample table:"})

      annotation_rows <- read_file(input$data_row_anno1$datapath, check.names=T)
      output$EntitieMatrix_VI <- DT::renderDataTable({
        DT::datatable(data = annotation_rows)
      })
      output$EntitieMatrix_VI_INFO <- renderText({"Entitie table:"})

      ## Do some checking
      snippetYes <- "<font color=\"#00851d\"><b>Yes</b></font>"
      snippetNo <-  "<font color=\"#ab020a\"><b>No</b></font>"
      snippetOrangeNo <- "<font color=\"#FFA500\"><b>No</b></font> But if you use any preprocessing other than `None`, those NAs will be removed"

      check0 <- ifelse(flag_csv,snippetYes,snippetNo)
      check1 <- ifelse(all(rownames(Matrix) == rownames(annotation_rows)),snippetYes,snippetNo)
      check2 <- ifelse(all(colnames(Matrix) == rownames(sample_table)),snippetYes,snippetNo)
      check3 <- ifelse(any(is.na(Matrix) == T),snippetOrangeNo,snippetYes)
      check4 <- ifelse(any(is.na(sample_table) == T),snippetNo,snippetYes)
      check5 <- ifelse(any(is.na(annotation_rows) == T),snippetNo,snippetYes)
      check6 <- ifelse(all(colnames(Matrix2) == colnames(Matrix)),snippetYes,snippetNo)

      if(check0 == snippetNo){
        # add help text
        check0 <- paste0(
          snippetNo,
          "\n\tMost likely: You had a xlsx and exported to csv but your excel is in ",
          "german\n\tand/or you use ',' as separators for decimal positions.\n\t",
          "Fix: change your decimal separator in Excel and re-export!"
        )
      }
      if(check5 == snippetNo){
        # Indicate columns with NA
        colsWithNa <- numeric()
        for(i in 1:ncol(annotation_rows)){
           if(any(is.na(annotation_rows[,i]) == T)){
             colsWithNa <- c(colsWithNa,i)
           }
        }
        check5 <- paste0(snippetNo,"\n\tFollowing columns are potentially problematic: ",paste0(colsWithNa, collapse = ", "))
      }
      if(check6 == snippetNo){
        # add help text
        check6 <- paste0(
          snippetNo,
          "\n\tA syntactically valid name consists of letters, numbers,\n\t",
          "the dot or underline characters and starts with a letter.\n\t",
          "Therefore '12345' is invalid, 'ID_12345' is valid.\n\t",
          "Remember to change the Sample ID everywhere (Matrix & Sample Table)."
        )
      }
      output$OverallChecks <- renderText({
         paste0(
           "Some overall Checks have been run:\n",
           "Data Matrix is a real csv (has ',' as separators:): ",check0,"\n",
           "Rownames of Matrix are the same as rownames of entitie table ",check1,"\n",
           "Colnames of Matrix are same as rownames of sample table ",check2," \n",
           "Matrix has no na ",check3,"\n",
           "Sample table no na ",check4,"\n",
           "Entitie table no na ",check5,"\n",
           "Sample IDs have valid names ", check6, "\n"
         )
      })
    }
  })

  observeEvent(input$refresh_file_input, {
    uploaded_from("file_input")
    shinyjs::click("refresh1")
  })

  observeEvent(input$refresh_precompiled, {
    uploaded_from("precompiled")
    shinyjs::click("refresh1")
  })

  observeEvent(input$refresh_metadata, {
    uploaded_from("metadata")
    shinyjs::click("refresh1")
  })

  observeEvent(input$EasyTestForUser,{
    uploaded_from("testdata")
    shinyjs::click("refresh1")
  })
  
## Do Upload ----
  observeEvent(input$refresh1,{
    req(data_input_shiny())
    par_tmp[[session$token]]['omic_type'] <<- input[[paste0("omic_type_", uploaded_from())]]
    omic_type(input[[paste0("omic_type_", uploaded_from())]])
    par_tmp[[session$token]]['addedGeneAnno'] <<- FALSE
    fun_LogIt(message = "## Data Selection {.tabset .tabset-fade}")
    fun_LogIt(message = "### Info")
    fun_LogIt(
      message = paste0("**DataInput** - Uploaded Omic Type: ", par_tmp[[session$token]]['omic_type'])
    )
    if(!(
      # Is Precompiled data used?
      (isTruthy(input$data_preDone) & uploaded_from() == "precompiled") |
      # Is File Input used?
      (isTruthy(input$data_matrix1) &
        isTruthy(input$data_sample_anno1) &
        isTruthy(input$data_row_anno1) &
        uploaded_from() == "file_input"
      ) |
      # Is Metadata used?
      (isTruthy(input$data_matrix_metadata) &
        isTruthy(input$metadataInput) &
        isTruthy(input$data_row_anno_metadata) &
        uploaded_from() == "file_input"
      ) |
      # Is Test Data used?
      uploaded_from() == "testdata"
    )){
      output$debug <- renderText("The Upload has failed, or you haven't uploaded anything yet")
    } else if (uploaded_from() == "testdata"){
      output$debug <- renderText({"The Test Data Set was used"})
    } else {
      show_toast(
        title = paste(par_tmp[[session$token]]['omic_type'],"Data Upload"),
        text = paste(par_tmp[[session$token]]['omic_type'],"-data upload was successful"),
        position = "top",
        timer = 1500,
        timerProgressBar = T
      )
      output$debug <- renderText({
        "<font color=\"#00851d\"><b>Upload successful</b></font>"
      })
      if(isTruthy(input$data_preDone)){
        # precomplied set used
        fun_LogIt(message = paste0(
          "**DataInput** - The used data was precompiled. Filename: \n\t",
          input$data_preDone$name
        ))
      } else {
        fun_LogIt(message = paste0(
          "The following data was used: \n\t",
          input$data_matrix1$name,"\n\t",
          input$data_sample_anno1$name,"\n\t",
          input$data_row_anno1$name
        ))

        fun_LogIt(message = paste0(
          "**DataInput** - The raw data dimensions are: ",
          paste0(dim(res_tmp[[session$token]]$data_original),collapse = ", ")
        ))
        
      }
      showTab(inputId = "tabsetPanel1", target = "Pre-processing")
    }
  })

## create data object ----
  data_input_shiny <- eventReactive(input$refresh1,{
    req(
      (isTruthy(input$data_preDone) & uploaded_from() == "precompiled") |
      # Is File Input used?
      (isTruthy(input$data_matrix1) &
        isTruthy(input$data_sample_anno1) &
        isTruthy(input$data_row_anno1) &
        uploaded_from() == "file_input"
      ) |
      # Is Metadata used?
      (isTruthy(input$data_matrix_metadata) &
        isTruthy(input$metadataInput) &
        isTruthy(input$data_row_anno_metadata) &
        uploaded_from() == "file_input"
      ) |
      # Is Test Data used?
      uploaded_from() == "testdata"
    )
    # initialize empty data_input object
    data_input <- list()
    # upload depending on where the button was clicked
    if(uploaded_from()=="file_input"){
      data_input <- list(
        Matrix = read_file(input$data_matrix1$datapath, check.names=T),
        sample_table = read_file(input$data_sample_anno1$datapath, check.names=T),
        annotation_rows = read_file(input$data_row_anno1$datapath, check.names=T)
      )
      # check if only 1 col in anno row,
      # add dummy col to ensure R does not turn it into a vector
      if(ncol(data_input$annotation_rows) < 2){
        data_input$annotation_rows$origRownames <- rownames(data_input$annotation_rows)
      }
      
      
      
    } else if(uploaded_from() == "metadata"){
      tmp_sampleTable <- fun_readInSampleTable(input$metadataInput$datapath)
      test_data_upload <- function(){
        tryCatch({
          data_input <- list(
            type = as.character(input[[paste0("omic_type_", uploaded_from())]]),
            Matrix = read_file(
              input$data_matrix1$datapath, check.names=T
              )[,rownames(tmp_sampleTable)],
            sample_table = tmp_sampleTable,
            annotation_rows = read_file(input$data_row_anno1$datapath, check.names=T)
            )
          return(data_input)
        },
        error = function(){
          print("Error! Names From SampleTable and Matrix do not fit")
          output$debug <- renderText({
            "<font color=\"#FF0000\"><b>Your Sample Names from the Metadata Sheet and from your Matrix do not match!! Data cannot be loaded</b></font>"
          })
          reset('metadataInput')
          return(NULL)
        })
      }
      data_input <- test_data_upload()

      
    } else if(uploaded_from() == "precompiled"){
      uploadedFile <- readRDS(file = input$data_preDone$datapath)
      if(any(names(uploadedFile) %in% input[[paste0("omic_type_", uploaded_from())]])){
        # This is a file precompiled before 14.March.2023
        data_input <- uploadedFile[[input[[paste0("omic_type_", uploaded_from())]]]]
      } else {
        data_input[[paste0(input[[paste0("omic_type_", uploaded_from())]],"_SumExp")]] <- uploadedFile
      }
    } else if(uploaded_from() == "testdata"){
      data_input <- readRDS(
        file = "www/Transcriptomics_only_precompiled-LS.RDS"
      )
      fun_LogIt(
        message = paste0("<font color=\"#FF0000\"><b>**Attention** - Test Data set used</b></font>")
      )
    } else {
      output$debug <- renderText({
        "<font color=\"#FF0000\"><b>Upload failed, please check your input.</b></font>"
      })
      return(NULL)
    }

    if(!any(class(data_input) == "SummarizedExperiment") & !any(grepl('SumExp',names(data_input))) ){
      summarized_experiment <- tryCatch(
        expr = {
          ## Lets Make a SummarizedExperiment Object for reproducibility and further usage
          sum_exp <- SummarizedExperiment(
            assays  = list(raw = data_input$Matrix),
            rowData = data_input$annotation_rows[rownames(data_input$Matrix),,drop=F],
            colData = data_input$sample_table
          )
          sum_exp
        },
        error = function(e){
          print("Error! Uploading via file input failed")
          output$debug <- renderText({
            "<font color=\"#FF0000\"><b>Uploading failed</b></font>: The uplaoded files could not be put into a SummarizedExperiment. Try the 'Inspect data' button for potential errors."
          })
          NULL
        }
      )
      if(is.null(summarized_experiment)){
        return(NULL)
      } else {
        data_input[[paste0(input[[paste0("omic_type_", uploaded_from())]],"_SumExp")]] <- summarized_experiment
      }
      #TODO make the copy and tab show process dependent if we get here a results object or 'simple' rds
    }
    # TODO SumExp only needed hence more restructuring needed
    res_tmp[[session$token]][['data_original']] <<- data_input[[paste0(input[[paste0("omic_type_", uploaded_from())]],"_SumExp")]]
    # Make a copy, to leave original data untouched
    res_tmp[[session$token]][['data']] <<- res_tmp[[session$token]]$data_original
    # Count up updating
    updating$count <- updating$count + 1

    colData(res_tmp[[session$token]]$data) <- DataFrame(
      as.data.frame(colData(res_tmp[[session$token]]$data)) %>%
      purrr::keep(~length(unique(.x)) != 1)
    )
    print(paste0(
      "Number. of anno options sample_table lost: ",
      ncol(res_tmp[[session$token]]$data_original) - ncol(res_tmp[[session$token]]$data)
    ))

    rowData(res_tmp[[session$token]]$data) <- DataFrame(
      as.data.frame(rowData(res_tmp[[session$token]]$data)) %>%
        purrr::keep(~length(unique(.x)) != 1)
    )
    
    # edit annotation columns such that if na is present in the row annotation,
    # the na gets replaced by the rowname
    for(i in 1:ncol(rowData(res_tmp[[session$token]]$data))){
      if(any(is.na(rowData(res_tmp[[session$token]]$data)[,i]))){
        rowData(res_tmp[[session$token]]$data)[is.na(rowData(res_tmp[[session$token]]$data)[,i]),i] <<- rownames(res_tmp[[session$token]]$data)[is.na(rowData(res_tmp[[session$token]]$data)[,i])]
      }
    }
    
    for(i in 1:ncol(rowData(res_tmp[[session$token]]$data_original))){
      if(any(is.na(rowData(res_tmp[[session$token]]$data_original)[,i]))){
        rowData(res_tmp[[session$token]]$data_original)[is.na(rowData(res_tmp[[session$token]]$data_original)[,i]),i] <<- rownames(res_tmp[[session$token]]$data_original)[is.na(rowData(res_tmp[[session$token]]$data_original)[,i])]
      }
    }
    
    print(paste0(
      "Number. of anno options annotation_rows lost: ",
      nrow(res_tmp[[session$token]]$data_original) - nrow(res_tmp[[session$token]]$data)
    ))

    return("DataUploadSuccesful")
  })
  #data_input_shiny = is the res object now which is global => not needed ?!
  print("Data Input done")
  
# Data Selection  ----
## Ui Section ----
  observe({
    req(data_input_shiny())
    isTruthy(res_tmp[[session$token]]$data)
    # Row
    output$providedRowAnnotationTypes_ui <- renderUI({shinyWidgets::virtualSelectInput(
      inputId = "providedRowAnnotationTypes",
      label = "Which annotation type do you want to select on?",
      choices = c(colnames(rowData(res_tmp[[session$token]]$data_original))),
      multiple = F,
      search = T,
      showSelectedOptionsFirst = T
    )})
    output$row_selection_ui <- renderUI({
      req(input$providedRowAnnotationTypes)
      if(is.numeric(
        rowData(res_tmp[[session$token]]$data_original)[,input$providedRowAnnotationTypes])
      ){
        selectInput(
          inputId = "row_selection",
          label = "Which entities to use? (Your input category is numeric, selection is currently only supported for categorical data!)",
          choices = c("all"),
          selected = "all",
          multiple = T
        )
      } else {
        shinyWidgets::virtualSelectInput(
          inputId = "row_selection",
          label = "Which entities to use? (Will be the union if multiple selected)",
          choices = c("High Values+IQR","all",unique(unlist(strsplit(rowData(res_tmp[[session$token]]$data_original)[,input$providedRowAnnotationTypes],"\\|")))),
          selected = "all",
          multiple = T,
          search = T,
          showSelectedOptionsFirst = T
        )
      }
    })
    output$propensityChoiceUser_ui <- renderUI({
      req(data_input_shiny())
      req(any(input$row_selection == "High Values+IQR"))
      numericInput(
        inputId = "propensityChoiceUser",
        label = "Specifcy the propensity for variablity & Expr",
        value = 0.85,
        min = 0,
        max = 1
      )
    })
    # Column /Sample
    output$providedSampleAnnotationTypes_ui <- renderUI({
      req(data_input_shiny())
      selectInput(
        inputId = "providedSampleAnnotationTypes",
        label = "Which annotation type do you want to select on?",
        choices = c(colnames(colData(res_tmp[[session$token]]$data_original))),
        selected = c(colnames(colData(res_tmp[[session$token]]$data_original)))[1],
        multiple = F
      )
    })
    output$sample_selection_ui <- renderUI({
      req(data_input_shiny(),isTruthy(input$providedSampleAnnotationTypes))
      selectInput(
        inputId = "sample_selection",
        label = "Which entities to use? (Will be the union if multiple selected)",
        choices = c(
          "all",
          unique(colData(res_tmp[[session$token]]$data_original)[,input$providedSampleAnnotationTypes])
        ),
        selected = "all",
        multiple = T
      )
    })
  })
  
## Log Selection ----
  observeEvent(input$NextPanel,{
    # Do actual selection before logging
    print(selectedData())
    # add row and col selection options
    fun_LogIt(message = "**DataSelection** - The following selection was conducted:")
    print(length(input$sample_selection))
    fun_LogIt(message = paste0(
      "**DataSelection** - Samples:\n\t DataSelection - based on: ",
      input$providedSampleAnnotationTypes,": ",
      paste(input$sample_selection,collapse = ", ")
    ))
    fun_LogIt(message = paste0(
      "**DataSelection** - Entities:\n\t DataSelection - based on: ",
      input$providedRowAnnotationTypes,
      ": ",paste(input$row_selection,collapse = ", ")
    ))
    if(!is.null(input$propensityChoiceUser)){
      # also record IQR if this + other selection was selected
      fun_LogIt(message = paste0(
        "**DataSelection** - IQR treshold: ",
        input$propensityChoiceUser
      ))
    }
    
    fun_LogIt(message = "### Publication Snippet")
    fun_LogIt(message = snippet_dataInput(data=res_tmp[[session$token]],
                                          params=par_tmp[[session$token]]))
    fun_LogIt(message = "<br>")
    showTab(inputId = "tabsetPanel1",target = "Pre-processing",select = T)
  })
  
  ## Do Selection ----  
  selectedData <- reactive({
    shiny::req(input$row_selection, input$sample_selection)
    par_tmp[[session$token]][["row_selection"]] <<- input$row_selection
    par_tmp[[session$token]][["sample_selection"]] <<- input$sample_selection
    par_tmp[[session$token]][["providedRowAnnotationTypes"]] <<- input$providedRowAnnotationTypes
    print("Alright do Row selection")

    selected <- c()

    if(any(input$row_selection == "all")){
      selected <- rownames(rowData(res_tmp[[session$token]]$data_original))
    } else if(!(length(input$row_selection) == 1 & any(input$row_selection == "High Values+IQR"))){
      selected <- unique(c(
        selected,
        rownames(rowData(res_tmp[[session$token]]$data_original))[
          which(rowData(res_tmp[[session$token]]$data_original)[,input$providedRowAnnotationTypes]%in%input$row_selection)
        ]
      ))
    }
    if(any(input$row_selection == "High Values+IQR")){
      if(length(input$row_selection) == 1){
        toKeep <- filter_rna(
          rna = assay(res_tmp[[session$token]]$data_original),
          prop = input$propensityChoiceUser
        )
        filteredIQR_Expr <- assay(res_tmp[[session$token]]$data_original)[toKeep,]
        selected <- rownames(filteredIQR_Expr)
      } else {
        toKeep <- filter_rna(
          rna = assay(res_tmp[[session$token]]$data_original)[selected,],
          prop = input$propensityChoiceUser
        )
        filteredIQR_Expr <- assay(res_tmp[[session$token]]$data_original)[toKeep,]
        selected <- intersect(selected, rownames(filteredIQR_Expr))
      }
      par_tmp[[session$token]]['propensity'] <<- input$propensityChoiceUser
      remove(filteredIQR_Expr)
    }

    # Column Selection
    samples_selected <- c()
    if(any(input$sample_selection == "all")){
      samples_selected <- colnames(assay(res_tmp[[session$token]]$data_original))
    }else{
      samples_selected <- c(
        samples_selected,
        rownames(colData(res_tmp[[session$token]]$data_original))[which(
          colData(res_tmp[[session$token]]$data_original)[,input$providedSampleAnnotationTypes] %in% input$sample_selection
          )]
        )
    }
    # Data set selection
    res_tmp[[session$token]]$data <<- res_tmp[[session$token]]$data_original[selected,samples_selected]
    par_tmp[[session$token]][['samples_selected']] <<- samples_selected
    par_tmp[[session$token]][['entities_selected']] <<- selected
    return("Selection Success")
  })
  
# Pre-processing after Selection ----
# Set Selected Data as Head to allow reiteration of pre-processing

## UI section ----
  # Update the batch effect UI based on the available columns
  output$batch_effect_ui <- renderUI({
    req(data_input_shiny())
    column_names <- colnames(colData(res_tmp[[session$token]]$data_original))
    filtered_column_names <- column_names[sapply(column_names, function(col) {
      length(unique(colData(res_tmp[[session$token]]$data_original)[[col]])) < nrow(colData(res_tmp[[session$token]]$data_original))
    })]
    if (input$PreProcessing_Procedure == "vst_DESeq") {
      filtered_column_names <- filtered_column_names[!filtered_column_names %in% c(input$DESeq_formula_main, input$DESeq_formula_sub)]
    }
    selectInput(
      inputId = "BatchEffect_Column",
      label = "Select Batch Effect Column",
      choices = c("NULL", filtered_column_names),
      selected = "NULL"
    )
  })
  output$DESeq_formula_main_ui <- renderUI({
    req(data_input_shiny())
    req(input$PreProcessing_Procedure == "vst_DESeq")
    selectInput(
      inputId = "DESeq_formula_main",
      label = paste0(
        "Choose main factor for desing formula in DESeq pipeline ",
        "(App might crash if your factor as only 1 sample per level)"
      ),
      choices = c(colnames(colData(res_tmp[[session$token]]$data))),
      multiple = F,
      selected = "condition"
    ) %>% helper(type = "markdown", content = "PreProcessing_DESeqMain")
  })
  output$DESeq_formula_sub_ui <- renderUI({
    req(data_input_shiny())
    req(input$PreProcessing_Procedure == "vst_DESeq")
    selectInput(
      inputId = "DESeq_formula_sub",
      label = paste0(
        "Choose other factors to account for",
        "(App might crash if your factor as only 1 sample per level)"
      ),
      choices = c(colnames(colData(res_tmp[[session$token]]$data))),
      multiple = T,
      selected = "condition"
    ) %>% helper(type = "markdown", content = "PreProcessing_DESeqSub")
  })

## Do preprocessing ----  
  selectedData_processed <- eventReactive(input$Do_preprocessing,{
    # only enter this when you actually click data
    req(input$Do_preprocessing > 0)
    waiter <- Waiter$new(
      id="data_summary",
      html = LOADING_SCREEN,
      color="#3897F147",
      hide_on_render=FALSE
    )
    waiter$show()
    print("Do Preprocessing")
    print(selectedData())
    addWarning <- ""
    par_tmp[[session$token]]['PreProcessing_Procedure'] <<- input$PreProcessing_Procedure
    # reset data to the selection that was done
    res_tmp[[session$token]]$data <<- res_tmp[[session$token]]$data_original[par_tmp[[session$token]][['entities_selected']],par_tmp[[session$token]][['samples_selected']]]

    print("Remove all entities which are constant over all samples")
    res_tmp[[session$token]]$data <<- res_tmp[[session$token]]$data[rownames(res_tmp[[session$token]]$data[which(apply(assay(res_tmp[[session$token]]$data),1,sd) != 0),]),]

    print(dim(res_tmp[[session$token]]$data))
    # explicitly set rownames to avoid any errors.
    # new object Created for res_tmp[[session$token]]
    res_tmp[[session$token]]$data <<- res_tmp[[session$token]]$data[rownames(res_tmp[[session$token]]$data),]
    par_tmp[[session$token]]['BatchColumn'] <<- input$BatchEffect_Column

    # Batch correction before preprocessing
    if (input$BatchEffect_Column != "NULL" & input$PreProcessing_Procedure != "vst_DESeq") {
      tryCatch({
        res_tmp[[session$token]]$data_batch_corrected <<- prefiltering(
          res_tmp[[session$token]]$data,
          par_tmp[[session$token]]$omic_type
        )
        assay(res_tmp[[session$token]]$data_batch_corrected) <<- sva::ComBat(
          dat = assay(res_tmp[[session$token]]$data_batch_corrected),
          batch = as.factor(colData(res_tmp[[session$token]]$data_batch_corrected)[,input$BatchEffect_Column])
        )
      }, error = function(e){
        error_modal(
          e, additional_text = "Batch correction failed. Make sure the batch effect column is correct!"
        )
        req(FALSE)
      })
    } else if (input$BatchEffect_Column != "NULL" & input$PreProcessing_Procedure == "vst_DESeq"){
      tryCatch({
        res_tmp[[session$token]]$data_batch_corrected <<- deseq_processing(
            data = tmp_data_selected,
            omic_type = par_tmp[[session$token]]$omic_type,
            formula_main = input$DESeq_formula_main,
            formula_sub = c(input$DESeq_formula_sub, input$BatchEffect_Column),
            session_token = session$token,
            batch_correct = T
          )
      }, error = function(e){
        error_modal(
          e, additional_text = paste0(
            "Batch correction using DESeq failed. Most likely due to linear dependencies ",
            "in the design matrix (one or more factors informing about another one).",
            "Make sure the batch effect column is correct and ",
            "that the design matrix is not singular!"
            )
        )
        req(FALSE)
      })
    } else {
      res_tmp[[session$token]]$data_batch_corrected <<- NULL
    }

    # preprocessing
    print(paste0("Do chosen Preprocessing:",input$PreProcessing_Procedure))
    tryCatch({
      if(input$PreProcessing_Procedure == "vst_DESeq"){
        res_tmp[[session$token]]$data <<- deseq_processing(
            data = res_tmp[[session$token]]$data,
            omic_type = par_tmp[[session$token]]$omic_type,
            formula_main = input$DESeq_formula_main,
            formula_sub = input$DESeq_formula_sub,
            session_token = session$token,
            batch_correct = F
          )
      } else {
        res_tmp[[session$token]]$data <<- preprocessing(
          data = res_tmp[[session$token]]$data,
          omic_type = par_tmp[[session$token]]$omic_type,
          procedure = input$PreProcessing_Procedure
        )
        if (!is.null(res_tmp[[session$token]]$data_batch_corrected)) {
          res_tmp[[session$token]]$data_batch_corrected <<- preprocessing(
            data = res_tmp[[session$token]]$data_batch_corrected,
            omic_type = par_tmp[[session$token]]$omic_type,
            procedure = input$PreProcessing_Procedure
          )
        }
      }
    }, error = function(e){
      error_modal(e)
      req(FALSE)
    })

    if(input$PreProcessing_Procedure == "filterOnly"){
      addWarning <- "<font color=\"#000000\"><b>Only Filtering of low abundant is done only if Transcriptomics or Metabolomics was chosen</b></font><br>"
    } else if(input$PreProcessing_Procedure == "none"){
      addWarning <- "<font color=\"#000000\"><b>No Pre-Processing done. Use on your own accord.</b></font><br>"
    } else{
      addWarning <- "<font color=\"#000000\"><b>Pre Filtering to remove low abundant entities done if Transcriptomics or Metabolomics was chosen</b></font><br>"
    }
    print(dim(res_tmp[[session$token]]$data))

    if(any(is.na(assay(res_tmp[[session$token]]$data)))){
      print("This might be problem due to mismatched Annotation Data?!")
      nrow_before <- nrow(assay(res_tmp[[session$token]]$data))
      nrow_after <- nrow(
        res_tmp[[session$token]]$data[complete.cases(assay(res_tmp[[session$token]]$data)),]
      )
      addWarning <- paste0(addWarning, "<font color=\"#FF0000\"><b>There were NA's after pre-processing, any row containg such was completly removed! (before/after): ",nrow_before,"/",nrow_after,"</b></font><br>")
      if(!(nrow_after > 0)){
        addWarning <- paste0(addWarning, "<br> <font color=\"#FF0000\"><b>There is nothing left, choose different pre-processing other-wise App will crash!</b></font><br>")
      }
      res_tmp[[session$token]]$data <<- res_tmp[[session$token]]$data[complete.cases(assay(res_tmp[[session$token]]$data)),]
    }
    print(colnames(res_tmp[[session$token]]$data))

    showTab(inputId = "tabsetPanel1", target = "Sample Correlation")
    showTab(inputId = "tabsetPanel1", target = "Significance Analysis")
    showTab(inputId = "tabsetPanel1", target = "PCA")
    showTab(inputId = "tabsetPanel1", target = "Heatmap")
    showTab(inputId = "tabsetPanel1", target = "Single Gene Visualisations")
    showTab(inputId = "tabsetPanel1", target = "Enrichment Analysis")
    
    # Count up updating
    updating$count <- updating$count + 1

    output$Statisitcs_Data <- renderText({
      shinyjs::click("SignificanceAnalysis-refreshUI",asis = T)
      shinyjs::click("single_gene_visualisation-refreshUI",asis = T)
      shinyjs::click("EnrichmentAnalysis-refreshUI",asis = T)
      shinyjs::click("Heatmap-refreshUI",asis = T)
      shinyjs::click("PCA-refreshUI",asis = T)
      shinyjs::click("sample_correlation-refreshUI",asis = T)
      paste0(
        addWarning,
        "The data has the dimensions of: ",
        paste0(dim(res_tmp[[session$token]]$data),collapse = ", "),
        "<br>","Be aware that depending on omic-Type, basic pre-processing has been done anyway even when selecting none",
        "<br","If log10 was chosen, in case of 0's present log10(data+1) is done",
        "<br","See help for details",
        "<br>",ifelse(any(as.data.frame(assay(res_tmp[[session$token]]$data)) < 0),"Be aware that processed data has negative values, hence no log fold changes can be calculated",""))
    })
    output$raw_violin_plot <- renderPlot({
      violin_plot(res_tmp[[session$token]]$data_original[par_tmp[[session$token]][['entities_selected']],par_tmp[[session$token]][['samples_selected']]],
                  color_by = input$violin_color)
      })
    output$preprocessed_violin_plot <- renderPlot({
      violin_plot(res_tmp[[session$token]]$data, 
                  color_by = input$violin_color)
      })
    par_tmp[[session$token]]['violin_color'] <<- input$violin_color
    waiter$hide()
    return("Pre-Processing successfully")
  })
  
## Log preprocessing ----
  observeEvent(input$Do_preprocessing,{
    print(selectedData_processed())
    if(par_tmp[[session$token]]$omic_type == "Transcriptomics"){
      tmp_logMessage <- "Remove anything which row Count <= 10"
    } else if (par_tmp[[session$token]]$omic_type == "Metabolomics"){
      tmp_logMessage <- "Remove anything which has a row median of 0"
    } else {
      tmp_logMessage <- "none"
    }
    fun_LogIt("## Pre Processing {.tabset .tabset-fade}")
    fun_LogIt(message = "### Info")
    fun_LogIt(
      message = "**PreProcessing** - Alaways done: removal of all entities which are constant over all samples"
    )
    fun_LogIt(
      message = paste0("**PreProcessing** - Preprocessing procedure -standard (depending only on omics-type): ",tmp_logMessage)
    )
    fun_LogIt(
      message = paste0(
        "**PreProcessing** - Preprocessing procedure -specific (user-chosen): ",
        ifelse(input$PreProcessing_Procedure == "vst_DESeq",paste0(input$PreProcessing_Procedure, "~",input$DESeq_formula_main),input$PreProcessing_Procedure)
      )
    )
    if(input$BatchEffect_Column != "NULL"){
      fun_LogIt(
        message = paste0(
          "**PreProcessing** - Batch Effect Correction: ",
          input$BatchEffect_Column
        )
      )
    }
    fun_LogIt(
      message = paste0(
        "**PreProcessing** - The resulting dimensions are: ",
        paste0(dim(res_tmp[[session$token]]$data),collapse = ", ")
      )
    )
    fun_LogIt(message = "### Publication Snippet")
    fun_LogIt(message = snippet_preprocessing(data=res_tmp[[session$token]],
                                              params=par_tmp[[session$token]]))
    fun_LogIt(message = "<br>")
  })

  # render plots and ui Parts
  output$violin_plot_color_ui <- renderUI({
    req(selectedData())
    selectInput(
      inputId = "violin_color",
      label = "Color the violin plot by:",
      choices = c(colnames(colData(res_tmp[[session$token]]$data_original))),
      selected = c(colnames(colData(res_tmp[[session$token]]$data_original)))[1],
      multiple = F
    )
  })
  output$debug <- renderText(dim(res_tmp[[session$token]]$data))

  ## Preprocessing save, Report and Code Snippet
  output$SavePlot_Preprocess <- downloadHandler(
    filename = function() {
      paste0("Preprocessing_ViolinPlot_", Sys.Date(), input$file_ext_Preprocess)
    },
    content = function(file) {
      # Create individual plots
      raw_plot <- violin_plot(
        res_tmp[[session$token]]$data_original[par_tmp[[session$token]][['entities_selected']], par_tmp[[session$token]][['samples_selected']]],
        color_by = input$violin_color
      ) + ggtitle("Count distribution per sample - raw") + theme(legend.position = "none")

      preprocessed_plot <- violin_plot(
        res_tmp[[session$token]]$data,
        color_by = input$violin_color
      ) + ggtitle("Count distribution per sample - preprocessed")

      # Arrange the plots side by side with more space for the right plot
      combined_plot <- grid.arrange(
        raw_plot,
        preprocessed_plot,
        ncol = 2,
        widths = c(1, 1.3)
      )

      # Save the combined plot
      ggsave(
        filename = file,
        plot = combined_plot,
        width = 16,  # Increase the width of the figure
        height = 8,  # Adjust height if necessary
        units = "in",
        device = gsub("\\.","",input$file_ext_Preprocess)
      )

      on.exit({
        file_path <- paste0("/www/",session$token,"/")
        tmp_filename <- paste0(
          getwd(),
          file_path,
          paste0(
            "Preprocessing_ViolinPlot_",
            format(Sys.time(), "%Y_%m_%d_%H_%M_%S"),
            input$file_ext_Preprocess
          )
        )
        raw_plot <- violin_plot(
          res_tmp[[session$token]]$data_original[par_tmp[[session$token]][['entities_selected']], par_tmp[[session$token]][['samples_selected']]],
          color_by = input$violin_color
        ) + ggtitle("Count distribution per sample - raw") + theme(legend.position = "none")

        preprocessed_plot <- violin_plot(
          res_tmp[[session$token]]$data,
          color_by = input$violin_color
        ) + ggtitle("Count distribution per sample - preprocessed")

        # Arrange the plots side by side with more space for the right plot
        combined_plot <- grid.arrange(
          raw_plot,
          preprocessed_plot,
          ncol = 2,
          widths = c(1, 1.3)
        )
        ggsave(
          filename = tmp_filename,
          plot = combined_plot,
          width = 16,  # Increase the width of the figure
          height = 8,  # Adjust height if necessary
          units = "in",
          device = gsub("\\.","",input$file_ext_Preprocess)
        )

        fun_LogIt(message = "## PreProcessing Violin Plot{.tabset .tabset-fade}")
        fun_LogIt(message = "### Info")
        fun_LogIt(message = paste0("**PreProcess** - The Samples were plotted after: ",input$violin_color))
        fun_LogIt(
          message = paste0("**PreProcess** - ![Violin Plot](",tmp_filename,")")
        )
        # no publication snippet as thats already in the log
      })
    }
  )

  observeEvent(input$only2Report_Preprocess,{
    notificationID <- showNotification("Saving...",duration = 0)
    tmp_filename <- paste0(
      getwd(),
      file_path,
      paste0(
        "Preprocessing_ViolinPlot_",
        format(Sys.time(), "%Y_%m_%d_%H_%M_%S"),
        input$file_ext_Preprocess
      )
    )
    raw_plot <- violin_plot(
      res_tmp[[session$token]]$data_original[par_tmp[[session$token]][['entities_selected']], par_tmp[[session$token]][['samples_selected']]],
      color_by = input$violin_color
    ) + ggtitle("Count distribution per sample - raw") + theme(legend.position = "none")

    preprocessed_plot <- violin_plot(
      res_tmp[[session$token]]$data,
      color_by = input$violin_color
    ) + ggtitle("Count distribution per sample - preprocessed")

    # Arrange the plots side by side with more space for the right plot
    combined_plot <- grid.arrange(
      raw_plot,
      preprocessed_plot,
      ncol = 2,
      widths = c(1, 1.3)
    )
    ggsave(
      filename = tmp_filename,
      plot = combined_plot,
      width = 16,  # Increase the width of the figure
      height = 8,  # Adjust height if necessary
      units = "in",
      device = gsub("\\.","",input$file_ext_Preprocess)
    )
    fun_LogIt(message = "## PreProcessing Violin Plot{.tabset .tabset-fade}")
    fun_LogIt(message = "### Info")
    fun_LogIt(message = paste0("**PreProcess** - The Samples were plotted after: ",input$violin_color))
    fun_LogIt(
      message = paste0("**PreProcess** - ![Violin Plot](",tmp_filename,")")
    )
    # no publication snippet as thats already in the log
    removeNotification(notificationID)
    showNotification("Saved!",type = "message", duration = 1)
  })

  output$getR_Code_Preprocess <- downloadHandler(
    filename = function() {
      paste0("ShinyOmics_Rcode2Reproduce_", Sys.Date(), ".zip")
    },
    content = function(file) {
      envList <- list(
        res_tmp = res_tmp[[session$token]],
        par_tmp = par_tmp[[session$token]]
      )
      temp_directory <- file.path(tempdir(), as.integer(Sys.time()))
      dir.create(temp_directory)

      write(
        getPlotCode(0.5),
        file.path(temp_directory, "Code.R")
      )

      saveRDS(envList, file.path(temp_directory, "Data.RDS"))

      zip::zip(
        zipfile = file,
        files = dir(temp_directory),
        root = temp_directory
      )
    },
    contentType = "application/zip"
  )

  # Sample Correlation ----
  # calling server without reactive it will be init upon start, with no update
  # of respective data inputs hence need of at least one reactive!
  sample_correlation_server(
    id = "sample_correlation",
    data = res_tmp[[session$token]],
    params = par_tmp[[session$token]]
  )
  # significance analysis ----
  significance_analysis_server(
    id = 'SignificanceAnalysis',
    data = res_tmp[[session$token]],
    params = par_tmp[[session$token]]
  )
  # PCA ----
  pca_Server(
    id = "PCA",
    data = res_tmp[[session$token]],
    params = par_tmp[[session$token]],
    reactive(input$row_selection)
  )
  # Heatmap ----
  heatmap_server(
    id = 'Heatmap',
    data = res_tmp[[session$token]],
    params = par_tmp[[session$token]],
    reactive(updating$count)
    )
  # Single Gene Visualisations ----
  single_gene_visualisation_server(
    id = 'single_gene_visualisation',
    data = res_tmp[[session$token]]
  )

  # Enrichment Analysis ----
  enrichment_analysis_Server(
    id = 'EnrichmentAnalysis',
    data = res_tmp[[session$token]],
    params = par_tmp[[session$token]],
    reactive(updating$count)
  )
}
